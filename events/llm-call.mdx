---
title: LLM Call Event
description: Captures prompt context, tools, responses, and usage.
---


The LLM call event anchors the cognition boundary: what the model saw and produced.

## Example

```json
{
  "event": "llm_call",
  "thread_id": "t1",
  "model": "gpt-4",
  "system_prompt": "You are a helpful assistant...",
  "messages": ["..."],
  "tools": ["..."],
  "response": {"...": "..."},
  "tokens": {"prompt": 1234, "completion": 567, "total": 1801},
  "latency_ms": 2340,
  "truncation_occurred": false
}
```

## Required fields

| Field | Purpose |
| --- | --- |
| `thread_id` | Join events across the decision loop |
| `model` | Model identity and version |
| `messages` | Prompt context the model saw |
| `response` | Model output and tool calls |

<Callout type="info">
LLM call events are necessary but insufficient for debugging agent cognition.
</Callout>
