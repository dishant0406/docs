---
title: "Quick Start"
description: "Get started with WhyOps in minutes"
---

# Quick Start Guide

<Warning>
**Development Status:** WhyOps is currently in active development. This guide describes the planned integration experience. Both proxy and SDK implementations are coming soon.
</Warning>

Get your agent debuggable in under 5 minutes with WhyOps.

## Prerequisites

Before you begin, ensure you have:
- Python 3.8+ or Node.js 16+
- An existing agent application
- API access to an LLM provider (OpenAI, Anthropic, etc.)

## Installation

<Tabs>
  <Tab title="Python">
    ```bash
    pip install whyops
    ```
  </Tab>
  
  <Tab title="Node.js">
    ```bash
    npm install whyops
    # or
    yarn add whyops
    ```
  </Tab>
</Tabs>

## Choose Your Integration Mode

WhyOps offers two integration paths:

<CardGroup cols={2}>
  <Card title="Proxy Mode" icon="bolt" href="/integration/proxy-setup">
    **Best for:** Quick setup, minimal code changes
    
    **Coverage:** 70-80% of decisions
    
    **Effort:** 5 minutes
  </Card>
  
  <Card title="SDK Mode" icon="code" href="/integration/sdk-setup">
    **Best for:** Deep visibility, production systems
    
    **Coverage:** 95%+ of decisions
    
    **Effort:** 30 minutes
  </Card>
</CardGroup>

## Option 1: Proxy Mode (Fastest)

Perfect for getting started quickly or proof-of-concept.

<Steps>
  <Step title="Set API Base URL">
    <Tabs>
      <Tab title="Python">
        ```python
        import os
        
        # Option 1: Environment variable
        os.environ["OPENAI_BASE_URL"] = "https://proxy.whyops.ai"
        os.environ["WHYOPS_API_KEY"] = "your_whyops_key"
        
        # Then use OpenAI as normal
        from openai import OpenAI
        client = OpenAI()
        ```
      </Tab>
      
      <Tab title="Node.js">
        ```javascript
        // Option 1: Environment variable
        process.env.OPENAI_BASE_URL = "https://proxy.whyops.ai";
        process.env.WHYOPS_API_KEY = "your_whyops_key";
        
        // Then use OpenAI as normal
        import OpenAI from 'openai';
        const client = new OpenAI();
        ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step title="Run Your Agent">
    ```bash
    python your_agent.py
    ```
    
    That's it! WhyOps is now capturing:
    - All LLM calls and responses
    - Tool definitions and calls
    - Basic execution flow
  </Step>
  
  <Step title="View Dashboard">
    Open the WhyOps dashboard at `https://app.whyops.ai` to see:
    - Real-time decision graph
    - LLM call traces
    - Tool execution timeline
  </Step>
</Steps>

### What Proxy Mode Captures

<Check>✅ Full LLM prompts and responses</Check>
<Check>✅ Tool definitions available to LLM</Check>
<Check>✅ Tool calls made by LLM</Check>
<Check>✅ Tool results returned to LLM</Check>
<Check>✅ Basic conversation flow</Check>

## Option 2: SDK Mode (Recommended)

For production systems and complete visibility.

<Steps>
  <Step title="Initialize WhyOps">
    <Tabs>
      <Tab title="Python">
        ```python
        from whyops import WhyOps
        
        whyops = WhyOps(api_key="your_whyops_key")
        
        # Optional: Enable auto-instrumentation
        whyops.auto_instrument()
        ```
      </Tab>
      
      <Tab title="Node.js">
        ```javascript
        import { WhyOps } from 'whyops';
        
        const whyops = new WhyOps({ apiKey: 'your_whyops_key' });
        
        // Optional: Enable auto-instrumentation  
        whyops.autoInstrument();
        ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step title="Instrument Your Tools">
    <Tabs>
      <Tab title="Python">
        ```python
        from whyops import tool
        
        @tool
        def search_web(query: str) -> str:
            """Search the web for information"""
            # Your implementation
            results = perform_search(query)
            return results
        
        @tool  
        def get_weather(city: str) -> dict:
            """Get weather for a city"""
            # Your implementation
            return fetch_weather(city)
        ```
      </Tab>
      
      <Tab title="Node.js">
        ```javascript
        import { tool } from 'whyops';
        
        const searchWeb = tool({
          name: 'search_web',
          description: 'Search the web for information',
          parameters: { query: 'string' }
        }, async (query) => {
          // Your implementation
          const results = await performSearch(query);
          return results;
        });
        ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step title="Track Memory Operations">
    <Tabs>
      <Tab title="Python">
        ```python
        from whyops import track_memory_retrieval
        
        @track_memory_retrieval
        def retrieve_context(query: str):
            # Your RAG implementation
            embeddings = embed(query)
            results = vector_db.search(embeddings, top_k=5)
            return results
        ```
      </Tab>
      
      <Tab title="Node.js">
        ```javascript
        import { trackMemoryRetrieval } from 'whyops';
        
        const retrieveContext = trackMemoryRetrieval(
          async (query) => {
            // Your RAG implementation
            const embeddings = await embed(query);
            const results = await vectorDb.search(embeddings, { topK: 5 });
            return results;
          }
        );
        ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step title="Run and Monitor">
    Your agent now has full cognitive tracing:
    ```bash
    python your_agent.py
    ```
    
    View complete traces at `https://app.whyops.ai`
  </Step>
</Steps>

### What SDK Mode Adds

<Check>✅ Tool retry tracking</Check>
<Check>✅ Tool failure root causes</Check>
<Check>✅ Memory retrieval decisions</Check>
<Check>✅ Planner state evolution</Check>
<Check>✅ Framework termination reasons</Check>
<Check>✅ Silent error detection</Check>

## Example: Complete Integration

Here's a full example with both modes:

<Tabs>
  <Tab title="Proxy Only">
    ```python
    import os
    from openai import OpenAI
    from langchain.agents import AgentExecutor, create_openai_functions_agent
    from langchain.tools import tool
    
    # Just set the proxy URL
    os.environ["OPENAI_BASE_URL"] = "https://proxy.whyops.ai"
    os.environ["WHYOPS_API_KEY"] = "your_key"
    
    # Everything else stays the same
    @tool
    def search_web(query: str) -> str:
        """Search for information"""
        return perform_search(query)
    
    client = OpenAI()
    agent = create_openai_functions_agent(...)
    executor = AgentExecutor(agent=agent, tools=[search_web])
    
    # Run normally - WhyOps captures automatically
    result = executor.invoke({"input": "Research climate policies"})
    ```
  </Tab>
  
  <Tab title="SDK Enhanced">
    ```python
    import os
    from openai import OpenAI
    from whyops import WhyOps, tool, track_memory_retrieval
    
    # Initialize WhyOps
    whyops = WhyOps(api_key="your_key")
    whyops.auto_instrument()  # Patches OpenAI client
    
    # Instrument tools with decorator
    @tool
    def search_web(query: str) -> str:
        """Search for information"""
        result = perform_search(query)
        return result
    
    # Track memory operations
    @track_memory_retrieval
    def get_relevant_docs(query: str):
        embeddings = embed(query)
        docs = vector_db.search(embeddings, top_k=5, threshold=0.7)
        return docs
    
    # Use normally
    from langchain.agents import AgentExecutor
    
    result = executor.invoke({"input": "Research climate policies"})
    
    # View trace in dashboard
    print(f"View trace: https://app.whyops.ai/trace/{whyops.current_thread_id}")
    ```
  </Tab>
</Tabs>

## Verifying Integration

After setup, verify WhyOps is working:

<CodeGroup>
```python Python
from whyops import verify_integration

status = verify_integration()
print(status)
# Output:
# {
#   "proxy_connected": True,
#   "api_key_valid": True,
#   "events_captured": 15,
#   "dashboard_url": "https://app.whyops.ai/thread/..."
# }
```

```javascript Node.js
import { verifyIntegration } from 'whyops';

const status = await verifyIntegration();
console.log(status);
// Output:
// {
//   proxyConnected: true,
//   apiKeyValid: true,
//   eventsCaptured: 15,
//   dashboardUrl: "https://app.whyops.ai/thread/..."
// }
```
</CodeGroup>

## Viewing Your First Trace

Once your agent runs, view the trace in the dashboard:

1. Navigate to `https://app.whyops.ai`
2. Click on your latest thread
3. See the complete decision graph:

```
[User Input] "Research climate policies"
    ↓
[Memory Retrieval] Found 18 docs, used top 4
    ↓ (scores: 0.91, 0.87, 0.82, 0.80)
[LLM Decision] Choose tool: search_web
    ↓
[Tool Call] search_web("climate policy economics")
    ↓ (retry 1: timeout)
    ↓ (retry 2: success, 1234ms)
[Tool Result] [economics data...]
    ↓
[LLM Synthesis] Generate response
    ↓
[Final Answer]
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Integration Modes" icon="diagram-project" href="/integration/comparison">
    Deep dive into proxy vs. SDK modes
  </Card>
  
  <Card title="Event Schema" icon="table" href="/architecture/event-schema">
    Understand what data WhyOps captures
  </Card>
  
  <Card title="State Replay" icon="clock-rotate-left" href="/features/state-replay">
    Learn to replay production failures
  </Card>
  
  <Card title="Best Practices" icon="star" href="/best-practices/thread-management">
    Optimize your WhyOps integration
  </Card>
</CardGroup>

## Getting Help

<Card title="Need Help?" icon="life-ring">
  - **Discord:** [discord.gg/whyops](https://discord.gg/whyops)
  - **Email:** support@whyops.ai
  - **Documentation:** [docs.whyops.ai](https://docs.whyops.ai)
</Card>

---

<Info>
**Ready to dive deeper?** Explore [Integration Modes](/integration/comparison) to choose the right approach for your needs.
</Info>